---
title: 'Unit 3 Walkthrough: School Leader Selection Mechanism'
subtitle: "ECI 589 Social Network Analysis and Education"
author: "Dr. Shaun Kellogg"
date: "`r format(Sys.Date(),'%B %e, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 4
    toc_float: yes
editor_options:
  markdown:
    wrap: 72
bibliography: lit/references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. PREPARE

For the Unit 3 Walkthrough: School Leader Selection Mechanisms is once
again visit guided by Alan Daly and colleagues as we attempt to
replicate some of the analyses described in Chapter 9: Network Data and
Statistical Models from Social Network Analysis and Education
[@carolan2014]. In this walkthrough we'll revisit and then move beyond
the visual and mathematical descriptions of networks explored so far to
uncover generative processes, or mechanisms, that attempt to explain how
school leaders select peers for collaboration or confidential exchanges.

More specifically, this walkthrough will cover the following topics
pertaining to each data-intensive workflow process:

1.  **Prepare**: Prior to analysis, we'll take a look at the context
    from which our data came, formulate some research questions, and get
    introduced the {statnet} R package for ERGMs.

2.  **Wrangle**: In section 2 we will learn how to work with matrices,
    how to dichotomize matrices, and how to convert matrices into more
    workable formats like our familiar edge-list.

3.  **Explore**: In section 3, we once again use the {tidygraph} package
    and the companion {ggraph} package to calculate basic summary stats
    for our network and will try to replicate and ideally improve upon
    the sociogram in our course text.

4.  **Model**: We wrap up our analysis in Section 4 by introducing
    exponential random graph modules used in Chapter 9 of @carolan2014,
    learn to check how well our model "fits our data" and examine
    diagnostics that might indicate our model has issues.

5.  **Communicate**: We briefly reflect on our walkthrough in
    preparation for our independent analysis next week.

## 1a. Review the Research

In [Social Network Analysis and Education: Theory, Methods &
Applications](https://methods.sagepub.com/book/social-network-analysis-and-education)
@carolan2014 makes the following distinctions between mathematical and
statistical approaches to social network analysis:

1.  **Mathematical approaches** focus on what a network of actors "looks
    like" by describing the network using sociograms and/or network
    measures such as reciprocity, centrality, and density. However,
    these approaches "tend to regard the measured relationships and
    their strengths as accurately reflecting the real, final, or
    equilibrium status of the network."

2.  **Statistical approaches**, or statistical inference, on the other
    hand, focuses on "assessing the reproducibility or likelihood of an
    observed pattern" with the goal of explaining and ultimately
    predicting network structures and outcomes.

For Unit 3, we move beyond previous "mathematical approaches" used so
far and explore the use of ERGMs as a "statistical approach" to network
analysis. Specifically, we will try to replicate the P\* models used in
Chapter 9 of @carolan2014 in order to test hypotheses about individual
and network characteristics that may explain who school leaders select
for collaboration and confidential exchanges.

### Research Questions

For this walkthrough, we will be using school leadership data were
collected at two school districts over 3 consecutive years that was used
to answer the following research questions:

1.  Is there a relationship between the frequency of collaboration
    between school leaders and how often they turn to each other to
    discuss issues of a confidential nature?
2.  Do school leaders prefer to collaborate with those with whom they
    have collaborated in the past, or is there some other reason?
3.  Does gender or some other individual attribute predicts confidential
    exchanges between school leaders, or does some previous relation
    have a stronger effect?
4.  Does collaboration between leaders explain one's level of trust in
    one's administrative colleagues?
5.  Can we distinguish among different groups of school leaders based on
    how frequently they collaborate, and if so, are these groupings
    related to the level at which they work (school versus district)?

### Data Collection

For each consecutive year, school district leaders were invited to
complete a survey that collected individual:

-   **Demographic information** (e.g., gender, ethnicity, marital
    status, age, years of experiences);

-   **Network relationships types** (e.g., collaboration, confidential
    exchanges, energy, expertise, leaders approached for support,
    work-related issues, input, recognition, best practices, and
    innovation);

-   **Frequency of interactions** they have with those nominated
    individuals on a four-point frequency scale ranging from 1 (the
    least frequent) to 4 (1--2 times a week);

-   **Leadership efficacy** items were designed based on the Principal
    Efficacy Scale used in Daly et al. (2011) and Tschannen-Moran and
    Gareis's (2004) studies. The efficacy scale includes 18 items rated
    on a 9-point Likert scale ranging from 1 (None at all) to 9 (A great
    deal);

-   **Trust** scale contains eight items rated on a 7-point Likert scale
    ranging from 1 (Strongly disagree) to 7 (Strongly agree) modified
    from Tschannen-Moran and Hoy (2003).

### Analyses

Two modeling techniques unique to network analysis and demonstrated in
Chapter 9 of @carolan2014 are the quadratic assignment procedure (QAP)
and Exponential Random Graph Models (ERGM):

-   **QAP/MR**: The quadratic assignment procedure (QAP) developed by
    Hubert (1987) and Krackhardt (1987b) tests the null hypothesis of no
    correlation between the two networks and adjusts for this dependence
    between networks by repeatedly permuting the order of rows and
    columns of one of the networks while keeping the other network
    intact. The QAP is based on regression models and permutation tests
    for valued (i.e., continuous) relational variables.

-   **P1 and P\* (P-Star)**: Both of these models are some of the first
    to make use of the ERGM, which provides a basis for comparing
    whether a network's observed structural properties occur more
    frequently than you could expect from chance alone. ERGMs can be
    used to model ties in complete networks but do so in a manner that
    explains the presence (or absence) of ties as a function of
    individual-and/or network-level characteristics. While QAP and
    MR-QAP procedures control for network structure through
    permutations, these ERGMs attempt to explain it.

## 1b. Key Findings

In response to research questions 1 & 2 from above, Carolyn reported
that "while collaboration in year 1 does not significantly predict
collaboration in year 3, confidential exchanges in year 1 does" and
suggested that "collaboration among school leaders provides an important
foundation for more sensitive, perhaps even deeper, relations (e.g.,
confidential exchanges) at a later point in time."

### **ðŸ‘‰ Your Turn** **â¤µ**

For our Unit 3 Walkthrough, we focus specifically on generative
processes, or micro-level mechanisms, the might help explain who school
leaders select to collaborate with or engage in confidential exchanges.
Review Chapter 9 of SNA and Education and report out on the findings
from the ERGM analysis in response to Research Question 3 below:

3.  **Does gender or some other individual attribute predicts
    confidential exchanges between school leaders, or does some previous
    relation have a stronger effect?**

    -   YOUR RESPONSE HERE

Based on what you know about networks and the context so far, what other
specific question(s) might the data and analyses described allow you to
address. For example, the concept of homophily, or the tendency for
people to seek out or form ties to those who are similar to themselves,
was introduced in our readings and hypotheses about homophily can easily
be tested using using ERGMs:

-   YOUR RESPONSE HERE

Save this question for later as you'll have a chance to empirically test
it by the end of this walkthrough.

## **1c.** Load Libraries

Recall that **packages**, or libraries, are shareable collections of R
code that can contain functions, data, and/or documentation and extend
the functionality of R. You can always check to see which packages have
already been installed and loaded into RStudio Cloud by looking at the
the Files, Plots, & Packages Pane in the lower right hand corner.

Let's go ahead and load the packages from Units 1 & 2 since we'll be
using them again in this walkthrough:

```{r}
library(readxl)
library(tidyverse)
library(igraph)
library(tidygraph)
library(ggraph)
library(janitor)
```

#### statnet ðŸ“¦

![](img/statnetlogo.png){width="20%"}

Similar to the collection of packages contained in the {tidyverse}
package, the Statnet Team [@handcock:statnet] has developed a suite of R
packages for the management, exploration, statistical analysis,
simulation and vizualization of network data. The statistical modeling
framework used in {statnet} relies on Exponential-family Random Graph
Models (ERGMs).

As noted in the [statnet
tutorial](http://statnet.org/Workshops/ergm_tutorial.html#The_statnet_Project)
by the same authors, the exponential-family random graph models (ERGMs)
are a general class of models based in exponential-family theory for
specifying the probability distribution for a set of random graphs or
networks. Within this framework, one can---among other tasks:

1.  Define a model for a network that includes covariates representing
    features like homophily, mutuality, triad effects, and a wide range
    of other structural features of interest;

2.  Obtain maximum-likehood estimates for the parameters of the
    specified model for a given data set;

3.  Test individual coefficients, assess models for convergence and
    goodness-of-fit and perform various types of model comparison; and

4.  Simulate new networks from the underlying probability distribution
    implied by the fitted model.

Let's load the {statnet} package that we'll be using in the Model
section of our walkthrough for bullets 1-3 above:

```{r}
library(statnet)
```

------------------------------------------------------------------------

# 2. WRANGLE

For our data wrangling this week, we'll focus on working with network
data stored as an adjacency matrix. Our primary goals for this section
are learning how to:

a.  **Import Data**. In this section, we use the {readxl} package from
    the tidyverse to read in a matrix and node .

b.  **Dichotomize a Matrix**. As described in Chapter 9, we'll recode
    our edge values to 1s and 0s changing our valued matrix to a binary
    matrix.

c.  **Create Network Graph**. Finally, we'll convert our matrix to an
    edge-list and store both our edges and node attributes as a network
    igraph object in preparation for analysis.

## 2a. Import Data

One of our primary goals is to replicate the ERGM analysis from Chapter
9: Network Data and Statistical Models [@carolan2014]. Specifically,
we'll aim to reproduce the results from **Table 9.4. Results of P1 and
P\*Analyses for the Dichotomized and Directed School Leaders
Confidential Exchanges Network Year 3.**

To do so, we'll need to import two Excel files from the [Social Network
Analysis and Education companion
site](https://studysites.sagepub.com/carolan/study/resources.htm). The
first file contains our edges stored as a square matrix (more on this
later) and the second file is a standard rectangular data frame that
contains attributes for each node, i.e. school leaders. These files are
included in the data folder of your R Studio project. A description of
each file from the companion website is linked above and each data file
is linked below:

1.  [**School Leaders Data Chapter
    9_d**](https://studysites.sagepub.com/carolan/study/materials/datasets/99472_ds10.xls)**.**Â This
    adjacency matrix reports on "confidential help" ties among 43 school
    leaders in year 3 of a three-year study. This is a directed valued
    (weighted) network measured on five-point scale ranging from 0 to 4,
    with higher values indicating more frequent collaborations (1--2
    times/week). These data are used throughout Chapter 9.

2.  [**School Leaders Data Chapter
    9_e**](https://studysites.sagepub.com/carolan/study/materials/datasets/99472_ds11.xlsx)**.**Â This
    rectangular matrix consists of four attribute vectors for 43 school
    leaders. Following the first ID column, the matrix includes an
    efficacy score, trust score, and indicators for whether one works at
    the district-level and is male (1 = yes, 0 = no). These attribute
    variables will be used as covariates in our ERGMs later in this
    walkthrough.

Since we are working with Excel files, we'll need to use the
`read_excel()` function from {readxl} tidyverse package to import our
data. Let's import the `School Leaders Data Chapter 9_e.xlsx` node file
located in the `data/` folder first:

```{r}
leader_nodes <- read_excel("data/School Leaders Data Chapter 9_e.xlsx", 
                           col_types = c("text", "numeric", "numeric", "numeric", "numeric")) %>%
  clean_names()

leader_nodes
```

Note that we specified the `ID` column as "text" and the remaining
columns as "numeric." By default, the `readxl()` function would have
recognized each column as numeric, but the first column indicates the
"names" for each school leader and we'll be using this column to assign
names to our columns and rows for our adjacency matrix in just a bit.

### **ðŸ‘‰ Your Turn** **â¤µ**

Recall from above that our relations, or edges, are stored as a valued
[adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix) in
which columns and rows consist of the same actors and each cell contains
information about the tie between each pair of actors. In our case, the
tie is a directed and valued "arc" where the value indicates the
strength of the relationship.

Use the `read_excel()` function to import the
`School Leaders Data Chapter 9_d.xlsx` file, add an argument setting the
column names to `FALSE` since our file is a simple matrix with no header
or column names, and assign the matrix to a variable named
`leader_matrix`:

**Hint:** Type `?read_excel` into the console and check the arguments
section to find the name of the argument used to set column headers.

```{r}
#YOUR CODE HERE
leader_matrix <- read_excel("data/School Leaders Data Chapter 9_d.xlsx", 
                            col_names = FALSE)
```

Use the code chunk below to inspect the matrix you just imported and
answer the questions that follow:

```{r}
leader_matrix
```

1.  Is our network a square matrix? What does this tell you about the
    number of nodes in our network?

    -   

2.  Does our network contain self-loops? How do you know?

    -   

3.  What do the values in each cell of our matrix indicate?

    -   

## 2a. Dichotomize Matrix

Since one of our goals is a crude replication of the analysis
demonstrated in Chapter 9, and since working with "valued networks" is a
little more complex than binary networks, which indicate just the
presence or absence of a relationship between two actors, we will need
to "dichotomize" our matrix. In practice this simply entails converting
our valued matrix to a binary matrix with cells containing just 1s or
0s.

In their article, [Valued Ties Tell Fewer Lies: Why Not To Dichotomize
Network Edges With Thresholds](https://arxiv.org/abs/1101.0788), Thomas
and Blitzstein (2018) highlight several reasons why the dichotomization
procedure is appealing in an investigation aside from convenience and
simplicity:

1.  **Use of Exclusively Binary Methods.** Several classes of models
    have been designed to incorporate binary information directly,
    including the exponential random graph model.

2.  **Ease of Input and Data Collection.** The need to classify
    continuously-valued quantities into a set of discrete groups is
    widespread throughout all of science and technology, particularly
    because of the associated need to make clear decisions based on this
    information.

3.  **Ease of Output in Graphical Representations.** The visual appeal
    of graphs and networks has contributed to much of the field's
    attention in the past decade. When plotting a graphical structure, a
    clever choice of threshold can illuminate which nodes are most
    central, which connections the most vital.

4.  **Sparsity of Structure.** In data where there are very few natural
    zeroes (if any), di- chotomization provides a way to select for a
    small number of connections which are thought to be of the greatest
    importance to the system, or to nominate a number of ties for more
    in-depth study.

5.  **Binning To Address Nonlinearity and Reduce Noise.** If there is a
    nonlinear relationship in the data, binning the data into distinct
    ordinal categories has many advantages, namely, the reduction of
    total mean-squared error, and a corresponding increase in power for
    detecting a true non-zero relationship over an improperly specified
    linear analysis.

As the title of their article suggests, however, @thomas2011valued argue
that the motivations for dichotomization should be revisited as
dichotomization produces a range of problematic issues.

With that in mind, and before we can dichotomize our "matrix," we first
need to convert it to a matrix object recognized by R using the
`as.matrix()` function. We can then check to data format of our
`leader_matrix` using the `class()` function:

```{r}
leader_matrix <- leader_matrix %>%
  as.matrix()

class(leader_matrix)
```

Both the collaboration and confidential help network data were
dichotomized by recoding values originally coded as a 3 and 4 recoded to
1, indicating the presence of a directed tie for both relations, and
zero otherwise.

To dichotmize our our matrix, the following code will "assign" 0's to
all values in our matrix that are less than or equal to 2, and 1's to
all values that are greater the or equal to 3:

```{r}
leader_matrix[leader_matrix <= 2] <- 0

leader_matrix[leader_matrix >= 3] <- 1
```

### Add Row and Column Names

Before we can convert to an edge-list, we will also need to add the
names of our nodes to the columns and rows of our matrix. These are
stored in the `ID` column of our `leader_node` data frame. We can use
the `$` operator to select these names and assign to our `leader_matrix`
using the `rownames()` and `colnames()` functions respectively:

```{r}
rownames(leader_matrix) <- leader_nodes$ID

colnames(leader_matrix) <- leader_nodes$ID
```

## 2c. Create Network with Attributes

To date in this course, we have only worked with edge-lists as a data
format for storing network data. Recall that edge-lists contain a row
for each dyad consisting of at minimum two columns with the name of each
actor, and which conveniently can also contain other information or
attributes about the relationship such as edge weight, timestamps, or
other contextual information as demonstrated in Unit 1.

Edge-lists also have the advantage of being easier to work with when
using network packages in R.

### Get Edges

The {igraph} package introduced in Unit 1 has a convenient
`get.data.frame()` function for extracting an edge list from a matrix,
but first we need to convert our matrix to an igraph network object.

```{r}
adjacency_matrix <- graph.adjacency(leader_matrix,
                                    diag = FALSE)

class(adjacency_matrix)
```

Note that we included the `diag = FALSE` argument which converts all
values along the diagonal to 0s, thereby removing self-loops. I believe
they may have been included when calculating the network descriptives
included in Table 9.1, and our own descriptives may not match exactly,
but we'll need to remove these from our network for the ERGM analysis so
this will save us a step.

Now we can use the `get.data.frame()` function to covert our matrix to a
standard edge-list, and :

```{r}
leader_edges <- get.data.frame(adjacency_matrix) %>% 
  mutate(from = as.character(from)) %>%
  mutate(to = as.character(to))


leader_edges
```

### **ðŸ‘‰ Your Turn** **â¤µ**

Recall from Unit 2 that we introduced the {tidygraph} package for
preparing and summarizing our Twitter network. Tidygraph includes the
full functionality ofÂ `igraph`Â in a tidy API giving you access to almost
all of theÂ `dplyr`Â verbs plus a few more, developed for use with
relational data.

Similar to Unit 2, use the `tbl_graph()` function to convert our
`leader_edges` and `leader_nodes` data frames into a network graph
object, by including the following arguments and supplying the
appropriate code:

-   `edges =` expects a data frame, in our case `leader_edges`,
    containing information about the edges in the graph. The nodes of
    each edge must either be in a `to` and `from` column, or in the two
    first columns like the data frame we provided.

-   `nodes =` expects a data frame, in our case `leader_nodes`,
    containing information about the nodes in the graph. If `to` and/or
    `from` are characters or names, like in our data frames, then they
    will be matched to the column named according to `node_key` in
    nodes, if it exists, or matched to the first column in the node
    list.

-   `directed =` specifies whether the constructed graph be directed.

```{r}
# YOUR CODE HERE
leader_graph <- tbl_graph(edges = leader_edges,
                          nodes = leader_nodes,
                          directed = TRUE)


leader_graph
```

Congrats! You made it to the end of data wrangling section and are ready
to start analysis!

------------------------------------------------------------------------

# 3. EXPLORE

In Section 3, we use the {tidygraph} package for retrieving network
descriptives and the {ggraph} package to create a network visualization
to help illustrate these metrics. Specifically, in this section we will:

a.  **Examine Basic Descriptives**. We focus primarily on actors and
    edges in this walkthrough, including whether or not ties were
    reciprocated and node degree, an important and fairly intuitive
    measure of centrality.

b.  **Make a Sociogram**. Finally, we wrap up the explore phases by
    learning to plot a network and tweak key elements like the size,
    shape, and position of nodes and edges to better at communicating
    key findings.

## 3a. Examine Descriptives

As noted in SNA and Education [@carolan2014], many analyses of social
networks are primarily descriptive and aim to either represent the
network's underlying social structure through data-reduction techniques
or to characterize network properties through network measures.

In the analyses described in Chapter 9, descriptives were limited to the
mean and standard deviation for: in-degree, out-degree, trust and
efficacy measures. The proportion of male leaders was also reported. For
section 3a, let's see if we can reproduce these descriptives.

### Calculate Node Degree

Recall that **degree** is the number of ties to and from an ego, or put
more simply, a the number of people to whome someone is connected. In a
directed network, **in-degree** is the number of connections or ties
received, whereas **out-degree** is the number of connections or ties
sent.

The `activate()` function from the {tidygraph} package allows us to
treat the nodes in our network object as if they were a standard data
frame to which we can then apply tidyverse functions such as `select()`,
`filter()`, and `mutate()`.

We can use the `mutate()` functions to create new variables for nodes
such as measures of degree, in-degree, and out-degree using the
`centrality_degree()` function in the {tidygraph} package.

Run the following code to add in- and out-degree measures to each of our
nodes and examine the output:

```{r}
leader_measures <- leader_graph %>%
  activate(nodes) %>%
  mutate(in_degree = centrality_degree(mode = "in")) %>%
  mutate(out_degree = centrality_degree(mode = "out"))

leader_measures
```

### **ðŸ‘‰ Your Turn** **â¤µ**

We now see that, in addition to the previously included attributes
`trust` and `efficacy`, in-degree and out-degree measures have been
added to the nodes in our network. But what if we also want to know to
total number of "alters" each "ego" is connected to, i.e. the total
number of individuals each school leader are connected to?

Modify the code below to calculate `degree` for each school leader in
our network. **Hint:** `centrality_degree` is a wrapper for
`igraph::degree()` and the `mode =` argument can be found in the
corresponding help documentation.

```{r}
leader_measures <- leader_graph %>%
  activate(nodes) %>%
  mutate(degree = centrality_degree(mode = "all")) %>%
  mutate(in_degree = centrality_degree(mode = "in")) %>%
  mutate(out_degree = centrality_degree(mode = "out"))

leader_measures
```

### Summarize Node Measures

We can also use the `activate()` function combined with the
`data.frame()` function to extract our new measures to a separate data
frame so we inspect our nodes individually and view some basic summary
statistics using the handy `summary()` function included in the R {base}
package.

```{r}
node_measures <- leader_measures %>% 
  activate(nodes) %>%
  data.frame()

summary(node_measures)
```

It looks like our summary stats for Year 3 confidential exchanges
network and attribute data are pretty close to those reported in Table
9.1 copied from @carolan2014. For example, our average total efficacy
and trust scores were 6.65 and 4.78 respectively, compared to 6.64 and
4.77 as reported in Chapter 9.

![](img/table-9-1.jpg){width="90%"}

The average in/out-degree for our school leaders data is 3.26, however,
which is a little lower than that reported by Carolyn. Again, this is
likely a function of our removal of self-loops. To test this theory, we
could simply change the `diag = FALSE` argument added to the
`graph.adjacency()` function above to `TRUE` to include self-loops and
then try rerunning all the code above.

#### School/District-Level Stats

Since we are now working with a standard data frame, we can also apply
[{dyplr}](https://dplyr.tidyverse.org/index.html) functions like
[`group_by()`](https://dplyr.tidyverse.org/reference/group_by.html) and
[`summarise()`](https://dplyr.tidyverse.org/reference/summarise.html) to
calculate basic summary stats such as counts, mean, and standard
deviation as follows:

```{r}
node_measures %>%
  group_by(district_site) %>%
  summarise(n = n(),
            mean = mean(in_degree), 
            sd = sd(in_degree)
            )
```

We see that our measures are pretty close, but not an exact match.
Again, this is likely due to the self-loops we excluded. For example,
our average in-degree for district-level (coded "1") and school-level
(coded "0") leaders is 4.66 and 2.36 respectively, but reported as 4.72
and 2.64 by @carolan2014.

### **ðŸ‘‰ Your Turn** **â¤µ**

Use the code chunk below and additional chunks if needed to try and
replicate the school and district level findings for out-degree, trust
and efficacy measures.

```{r}
node_measures %>%
  group_by(district_site) %>%
  summarise(n = n(),
            mean = mean(out_degree), 
            sd = sd(out_degree)
            )

node_measures %>%
  group_by(district_site) %>%
  summarise(n = n(),
            mean = mean(trust), 
            sd = sd(trust)
            )

node_measures %>%
  group_by(district_site) %>%
  summarise(n = n(),
            mean = mean(efficacy), 
            sd = sd(efficacy)
            )
```

How close your result to those reported by Carolyn Table 9.1?

-   YOUR RESPONSE HERE

## 3b. Visualize Network

In Chapter 9, @carolan2014 depictgs a directed and dichotomous sociogram
of the **collaboration** network for year 3 is shown in .

![](img/figure-9-1.jpg){width="90%"}

### **ðŸ‘‰ Your Turn** **â¤µ**

Try creating a **Year 3 Confidential Exchange Network** by modifying the
code below and tweaking the included function/arguments or adding new
ones for
[layouts](https://ggraph.data-imaginist.com/articles/Layouts.html),
[nodes](https://ggraph.data-imaginist.com/articles/Nodes.html), and
[edges](https://ggraph.data-imaginist.com/articles/Edges.html) to make
our plot either more "aesthetically pleasing" or more purposeful in what
it's trying to communicate.

```{r}
#YOUR CODE HERE
leader_measures %>%
ggraph(layout = "fr") + 
  geom_node_point() +
  geom_edge_link() + 
  theme_graph()
```

After you are satisfied with your sociogram, answer the following
questions?

1.  How is the Year 3 confidential exchange network similar to the
    collaboration network? How is it different?

    -   YOUR RESPONSE HERE

Congrats! You made it to the end of the Explore section and are ready to
learn a little ab out modeling network selection processes using ERGMs!
Before proceeding further, knit your document and check to see if you
encounter any errors.

------------------------------------------------------------------------

# 4. MODEL

Recall from @carolan2014 that **Exponential Random Graph Models**
provide a means to compare whether a network's observed structural
properties occur more frequently than you could expect from chance
alone. More specifically, ERGMS provide a way to determine whether
network properties (e.g., reciprocity) occur by chance as a result of
other network properties (e.g., density) or whether the observed
properties are unlikely given other parameters in the network.

While the technical aspects of estimating ERGMs are complex, their
interpretation is pretty straightforward. In this section we are
interested exploring how these models be used make inferences about the
social processes at work in the School Leaders data. For example, in
this section we will explore the following questions:

-   If one school leader turns to another to discuss something
    confidential, is the latter likely to reciprocate?

-   Are school leaders more likely to confide in someone if they both
    confide in the same school leader?

-   Do a leader's gender and efficacy score, predict a confidential
    exchange between two leaders?

## 4a. Loading Network Data

As we've discovered in this course, network data can come in many
different forms --- ties can be stored as edgelists or matrices, saved
as .csv or excel files, and converted to a variety of network R objects;
attributes for the nodes, ties and dyads in can also various forms and
added in various ways to objects in R. For the {ergm} package, however,
data will need to be transformed into a `network` object --- the format
that statnet uses to store and work with network data.

Fortunately, we have already prepared our data for quick conversion to a
`network` object and can supply just a couple arguments to the
`as.network()` function from the {network} package:

-   `x =` a matrix giving the network structure in adjacency, incidence,
    or edgelist form;

-   `vertices` = an optional`data.frame` containing the vertex
    attributes. The first column is assigned to the `"vertex.names"` and
    additional columns are used to set vertex attributes using their
    column names.

Similar to the `tbl_graph` function from {tidygraph} that we used above,
let's add our `leader_edges` edge-list and our `leader_nodes` data frame
as the `x =` and `vertices =` attributes in the `as.network()` function
and assign to a new object called `leader_network`:

```{r}
leader_network <- as.network(leader_edges,
                             vertices = leader_nodes)

leader_network
```

Note that we could also have supplied our `leader_matrix` as the first
argument, but using and edgelist vastly simplifies the process of adding
node attributes.

Let's also check the be sure that our `leader_network` is indeed a
`network` object by using the `class()` function to identify object
type:

```{r}
class(leader_network)
```

So far so good! Let's start building our first ERGM model!

## 4b. Estimate the ERGM Model

We'll begin by running a simple model both to demonstrate the most
commonly used functions for ERGMs and also to replicate the approach in
Chapter 9 of @carolan2014.

The syntax for specifying a model in theÂ `ergm`Â package followsÂ **R**'s
formula convention:
`my_network ~ ergm_term_1 + ergm_term_2 + ergm_term_3` and so forth.

This syntax is used for both theÂ `summary`Â andÂ `ergm`Â functions.

-   TheÂ `summary`Â function simply returns the numerical values of the
    network statistics in the model.

-   TheÂ `ergm`Â function estimates the model with those statistics.

As noted by the [Statnet Development
Team](http://statnet.org/Workshops/ergm_tutorial.html#The_summary_and_ergm_functions,_and_supporting_functions):

> It is good practice to run aÂ `summmary`Â command on any model before
> fitting it withÂ `ergm`. This is the ERGM equivalent of performing some
> descriptive analysis on your covariates. This can help you make sure
> you understand what the term represents, and it can help to flag
> potential problems that will lead to poor modeling results.

### Network Structure Parameters

Let's start with with a simple model similar to the P~1~ model in Table
9.4. This model contains the ergm-term **`edges`** that represents the
total number of edges in the network, and the ergm-term **`mutual`**
that examines the tendency for ties to be reciprocated, i.e.
"mutuality".

```{r}
summary(leader_network ~ edges + mutual)
```

We see from our summary that our `leader_network` consists of 143 edges
and 36 reciprocated dyads.

Since the `ergm()` function automatically uses a stochastic MCMC-based
estimation algorithm, use the `set.seed()` function and set the value to
589 (note this could be any number besides our course number) so we
produce the same results each time.

Now let's estimate our model, save the results as `ergm_mod_1`, and use
the `summary()` function again to take a look at our estimates. Also,

```{r, message=FALSE}
set.seed(589)

ergm_mod_1 <-ergm(leader_network ~ edges + mutual)

summary(ergm_mod_1)
```

Since ERGMs predict the presence of a network tie, with estimates
indicating the importance of each to the presence of a tie, estimated
coefficients can be explained in terms similar to logistic regression.
That is, positive significant coefficients indicate that the
corresponding parameters in the observed network (e.g. reciprocated ties
between school leaders, controlling for all other parameters in the
model, occur more than would be expected by chance, thus increasing the
likelihood that a tie will occur, and vice-versa for negative
coefficients.

After several iterations, we see that our model finally converges and
suggest that the estimates for our `edges` and `mutual` terms are
statistically significant. The negative estimate for the `edge`
paramter, as noted by @carolan2014, implies that the probability of a
confidential exchange tie in year 3 is relatively low. The reciprocity
parameter, on the other hand, is 3.11 in our model, and indicates a
strong tendency for confidential-exchange ties to be reciprocated.

Now let's add an ergm-term for transitivity. Modeling transitivity, or
the "friend of a friend" phenomenon in social networks, is both
computationally intensive because of the all the possible "triangles" in
a directed network, and also very prone to model degeneration, i.e. when
models that fail to converge by reaching a value expected by the
parameters included in the model.

Ergm-terms for transitivity such as `triangles` and `transitive` in
particular are prone to model degeneration. Fortunately, the {ergm}
package includes a "more robust way of modeling triangles: the
geometrically-weighed edgewise shared partner term (GWESP)."

Let's add the `gwesp` term to our model with the suggested defaults from
the Statnet Tutorial section on [What it looks like when a model
fails](http://statnet.org/Workshops/ergm_tutorial.html#What_it_looks_like_when_a_model_fails)
and take a look at the summary first:

```{r}
summary(leader_network ~ edges + 
          mutual +
          transitive +
          gwesp(0.25, fixed=T))
```

As you can see, we have 202 transitive triad types.

Now lets run our model including transitivity and take a look at our
estimates. Note that this make take a couple minutes to run. If you'd
like to watch the number of iterations of the model set
`message = TRUE`.

```{r, message=FALSE}
ergm_mod_2 <-ergm(leader_network ~ edges + 
                    mutual +
                    gwesp(0.25, fixed=T))

summary(ergm_mod_2)
```

Contrary to the analysis in Chapter 9, our model so far suggest that
there is a tendency toward transitivity, that is a confidential exchange
is likely to occur between two people who both have a confidential
exchange with the same individual.

At this point, however, we have only focused on structural mechanisms
inherent to networks themselves, or "global features" of the graph
independent of actors, and have not looked at individual attributes
among actors that may be shaping out network.

### Actor Attribute Parameters

As noted by @carolan2014, ERGMs have advanced to the point where actor
attributes, or actor-level covariates, can now be incorporated into
model estimation, such as individuals' demographic (e.g., gender) or
behavioral (e.g., efficacy) characteristics. These two attributes
examined in Chapter 9 with leadership efficacy measured by survey items
based on the [Principal Efficacy
Scale](https://wmpeople.wm.edu/asset/index/mxtsch/pse).

The attributes were included as both sender and receiver effects, which
again can be very computationally intensive and thus timely to run,
while sometimes prone to model degeneracy without some model fine
tuning.

To simplify this approach, I've include these attributes using the
`nodefactor()` and `nocov()` ergm-terms respectively which allow us to
test whether those who are Male or have higher efficacy scores are more
likely to either send or receive a confidential exchange.

```{r, message=FALSE}
ergm_3 <- ergm(leader_network ~ edges +
                 mutual +
                 gwesp(0.25, fixed=T) +
                 nodefactor('male') +
                 nodecov('efficacy')
               )
  
  
summary(ergm_3)
```

Although there appears to be a very slight, though not statistically
significant tendency towards male leaders being more likely to send or
recieve ties, the primary drivers of network formation appear to be
structural features of the network including reciprocity and
transitivity.

Sadly, we were not able to replicate the findings from @carolan2014, but
we also did not replicate their model exactly, nor did we fine tune our
model parameters. Regardless, this provided a practical exercise for
demonstrating ERGMs.

### **ðŸ‘‰ Your Turn** **â¤µ**

Before moving on to checking the goodness of fit for our final model,
try testing a new model by modifying or adding your own ergm-term. For
example, to test for homophily among gender, the `ergm()` function
includes a `nodematch()` argument that could be used to see if school
leaders are more likely to confide in colleagues of their own gender.

You can look at a [table of common
ergm-terms](http://statnet.org/nme/d2-ergmterms.html) or type
"ergm-terms" into the help menu of the files pane for some suggested
examples.

```{r, message=FALSE}
#YOUR CODE HERE
ergm_4 <- ergm(leader_network ~ edges +
                 mutual +
                 gwesp(0.25, fixed=T) +
                 nodematch('male') +
                 nodecov('efficacy')
               )
  
  
summary(ergm_4)
```

Once you've checked the summary of your model estimates, write your
interpretation of the results below:

-   YOUR RESPONSE HERE

## 4c. Check Model Fit

One test of whether an ergm model is a "good fit" fo the data is "how
well it reproduces the observed global network properties *that are not
in the model*." This can be accomplished by choosing a network statistic
that is not in the model, and comparing the value of this statistic
observed in the original network to the distribution of values we get in
simulated networks from our model, using the `gof()` function to test
the goodness-of-fit.

### The GOF Function

The `gof()` function is a bit different than the `summary()` and
`ergm()` functions, in that it only takes 3 ergm-terms as arguments:
degree, esp (edgwise share partners), and distance (geodesic distances).
Each of these terms captures an aggregate network distribution, at
either the node level (degree), the edge level (esp), or the dyad level
(distance).

Let's go ahead and run the `gof()` function on our `ergm_3` model and
plot the results:

```{r}
ergm_3_gof <- gof(ergm_3)

plot(ergm_3_gof)
```

Overall, the model appears to fit reasonably well in that black line in
our charts (the actual observed network measures) closely follows the
aggregate measures generated from the simulations, or permutations of
our network.

### Check MCNC Diagnostics

One final check on our model is to examine the Monte-Carlo Markov Chain
(MCMC) diagnostics to make sure our model is not heading of in the wrong
direction and likely to never produce a network similar to what was
observed, which is referred to as "model degeneracy." As the statnet
authors note:

> When a model is not a good representation of the observed network, the
> simulated networks produced in the MCMC chains may be far enough away
> from the observed network that the estimation process is affected. In
> the worst case scenario, the simulated networks will be so different
> that the algorithm fails altogether.

Fortunately, our models did not fail to converge, the AIC and BIC
indicators seemed to improve with each term added to the model, and the
goodness-of-fit seemed to somewhat mirror the global features of our
network.

Let run the `mcmc.diagnostics()` function on our final model anyways and
check the results:

```{r}
mcmc.diagnostics(ergm_3)
```

One simple heuristic for interpreting `mcmc.diagnostics()` results is
too look for "balance." The charts with all the squiggles, to use a
non-technical term, should have a scale that ideally is centered on 0
and have roughly straight line running through it, while the chart that
looks like a simple line graph should also be ideally centered at 0 and
roughly normally distributed on both ends. Overall, the diagnostics
indicate there is room for improvement but nothing is wildly off and
hence our model did not fail to converge.

### **ðŸ‘‰ Your Turn** **â¤µ**

Use the code chunk below to check the model fit and diagnostics for the
model the you created in [4b. Estimate the ERGM Model]:

```{r}
#YOUR CODE HERE
```

------------------------------------------------------------------------

# 5. COMMUNICATE

For your Independent Analysis assignment for Unit 3 next week, you'll
create either a simple report or slide deck using an R Markdown document
just like this to share out some key findings from your analysis.
Regardless of whether you plan to talk us through your analysis and
findings with a presentation or walk us through with a brief written
report, your presentation or report should address the following
questions:

1.  **Purpose**. What question or questions are guiding your analysis?
    What did you hope to learn by answering these questions and why
    should your audience care about your findings?

2.  **Methods**. What data did you selected for analysis? What steps did
    you take took to prepare your data for analysis and what techniques
    you used to analyze your data? These should be fairly explicit with
    your embedded code.

3.  **Findings**. What did you ultimately find? How do your "data
    products" help to illustrate these findings? What conclusions can
    you draw from your analysis?

4.  **Discussion**. What were some of the strengths and weaknesses of
    your analysis? How might your audience use this information? How
    might you revisit or improve upon this analysis in the future?

### **ðŸ‘‰ Your Turn** **â¤µ**

Now that you've become more familiar with this dataset and the social
network perspective, what other aspects of this dataset, or a dataset
you are interested in exploring, could you investigate using the
approaches demonstrated in Chapter 9?

-   YOUR RESPONSE HERE

What specific research questions might you ask that would be helpful for
being understanding and improving learning, or the context in which the
data is collected?

-   YOUR RESPONSE HERE

### ðŸ§¶ Knit & Check âœ…

Congrats! You've finished the Unit 3 Guided Walkthrough and are ready
for your independent analysis next week!

To complete this assignment, knit your document and send me an email at
sbkellog\@ncsu.edu letting me know you're all set.
